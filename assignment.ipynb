{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 Prompt Engineering for Large Language Models (LLMs) [4 marks]\n",
    "Questions\n",
    "\n",
    "1. Demonstrate how to use Zero-Shot Learning and Few-Shot Learning to classify human activities based on the featurized accelerometer data. Qualitatively demonstrate the performance of Few-Shot Learning with Zero-Shot Learning. Which method performs better? Why?  **[1 marks]**\n",
    "2. Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why? **[1 marks]**\n",
    "3. What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data? **[1 marks]**\n",
    "4. What does the model classify when given input from an entirely new activity that it hasn't seen before? **[0.5 mark]**\n",
    "5. Test the model with random data (ensuring the data has the same dimensions and range as the previous input) and report the results. **[0.5 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "Groq_Token = os.getenv('api_key')\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model_name = \"llama3-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data \n",
    "\n",
    "file1_laying =  pd.read_csv(\"Combined/Test/LAYING/Subject_2.csv\")\n",
    "file2_walking = pd.read_csv(\"Combined/Test/WALKING/Subject_2.csv\")\n",
    "file3_sitting=  pd.read_csv(\"Combined/Test/SITTING/Subject_2.csv\")\n",
    "file4_standing=  pd.read_csv(\"Combined/Test/STANDING/Subject_2.csv\")\n",
    "file5_upstairs=  pd.read_csv(\"Combined/Test/WALKING_UPSTAIRS/Subject_2.csv\")\n",
    "file6_downstairs=  pd.read_csv(\"Combined/Test/WALKING_DOWNSTAIRS/Subject_2.csv\")\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(file1_laying).head(100)\n",
    "df2 = pd.DataFrame(file2_walking).head(100)\n",
    "df3 = pd.DataFrame(file3_sitting).head(100)\n",
    "df4 = pd.DataFrame(file4_standing).head(100)\n",
    "df5 = pd.DataFrame(file5_upstairs).head(100)\n",
    "df6 = pd.DataFrame(file6_downstairs).head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data for few shot prompt examples\n",
    "\n",
    "laying_train = pd.read_csv(\"Combined/Train/LAYING/Subject_1.csv\")\n",
    "sitting_train = pd.read_csv(\"Combined/Train/SITTING/Subject_1.csv\")\n",
    "standing_train = pd.read_csv(\"Combined/Train/STANDING/Subject_1.csv\")\n",
    "walking_train = pd.read_csv(\"Combined/Train/WALKING/Subject_1.csv\")\n",
    "downstairs_train = pd.read_csv(\"Combined/Train/WALKING_DOWNSTAIRS/Subject_1.csv\")\n",
    "upstairs_train = pd.read_csv(\"Combined/Train/WALKING_UPSTAIRS/Subject_1.csv\")\n",
    "\n",
    "laying_df = pd.DataFrame(laying_train).head(100)\n",
    "sitting_df = pd.DataFrame(sitting_train).head(100)\n",
    "standing_df = pd.DataFrame(standing_train).head(100)\n",
    "walking_df = pd.DataFrame(walking_train).head(100)\n",
    "downstairs_df = pd.DataFrame(downstairs_train).head(100)\n",
    "upstairs_df = pd.DataFrame(upstairs_train).head(100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify the activities as follows:\n",
      "\n",
      "**Data 1:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. This pattern is consistent with the activity of **Standing**.\n",
      "\n",
      "**Data 2:**\n",
      "The accelerometer data shows a significant variation in the x-axis, with values ranging from approximately 0.7 to 1.15. This suggests a high level of movement in the x-axis, which is consistent with the activity of **Walking**. The y and z axes show relatively smaller variations, which further supports this classification.\n",
      "\n",
      "**Data 3:**\n",
      "The accelerometer data shows a relatively stable pattern with small variations in the x, y, and z axes. The values are mostly within a small range, indicating a low level of movement. However, the x-axis values are slightly higher than those in Data 1, which suggests a slightly more upright posture. This pattern is consistent with the activity of **Sitting**.\n",
      "\n",
      "In summary, the classifications are:\n",
      "\n",
      "* Data 1: **Standing**\n",
      "* Data 2: **Walking**\n",
      "* Data 3: **Sitting**\n"
     ]
    }
   ],
   "source": [
    "# Zero shot demonstration\n",
    "\n",
    "zero_shot_prompt = f\"\"\"\n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "Here is the accelerometer data:\n",
    "{df1}, {df2}, {df3}\n",
    "\n",
    "Please classify the activity for these three accelerometer data.\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_answer = llm.invoke(zero_shot_prompt)\n",
    "print(zero_shot_answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify each dataset into one of the six activities: Walking, Standing, Sitting, Laying, Walking Upstairs, or Walking Downstairs.\n",
      "\n",
      "**Dataset 1:**\n",
      "        accx      accy      accz\n",
      "0  -0.185673  0.737995  0.663749\n",
      "...\n",
      " Sentiment Label: Laying\n",
      "Reasoning: The accy values are consistently high (> 0.7), indicating a relatively stable vertical acceleration, which is characteristic of laying down.\n",
      "\n",
      "**Dataset 2:**\n",
      "        accx      accy      accz\n",
      "0   1.153546 -0.249716 -0.084946\n",
      "...\n",
      " Sentiment Label: Walking\n",
      "Reasoning: The accx values are varying and relatively high (> 1.0), indicating a dynamic movement, which is characteristic of walking. The accy values are also varying, suggesting a change in direction.\n",
      "\n",
      "**Dataset 3:**\n",
      "        accx      accy      accz\n",
      "0   1.011120 -0.105541  0.162614\n",
      "...\n",
      " Sentiment Label: Standing\n",
      "Reasoning: The accx values are relatively stable and high (> 1.0), indicating a vertical acceleration, which is characteristic of standing. The accy values are relatively low and stable, suggesting a stable posture.\n",
      "\n",
      "**Dataset 4:**\n",
      "        accx      accy      accz\n",
      "0   0.999192 -0.264935  0.125616\n",
      "...\n",
      " Sentiment Label: Walking\n",
      "Reasoning: The accx values are varying and relatively high (> 0.9), indicating a dynamic movement, which is characteristic of walking. The accy values are also varying, suggesting a change in direction.\n",
      "\n",
      "**Dataset 5:**\n",
      "        accx      accy      accz\n",
      "0   1.085438 -0.727962 -0.413233\n",
      "...\n",
      " Sentiment Label: Walking Downstairs\n",
      "Reasoning: The accx values are varying and relatively high (> 1.0), indicating a dynamic movement, which is characteristic of walking downstairs. The accy values are consistently negative and relatively high, suggesting a downward acceleration.\n",
      "\n",
      "**Dataset 6:**\n",
      "        accx      accy      accz\n",
      "0   0.793270 -0.267093 -0.012385\n",
      "...\n",
      " Sentiment Label: Sitting\n",
      "Reasoning: The accx values are relatively stable and low (< 1.0), indicating a relatively stable horizontal acceleration, which is characteristic of sitting. The accy values are relatively low and stable, suggesting a stable posture.\n",
      "\n",
      "Please note that these classifications are based on the patterns and characteristics of the provided sample datasets and may not be 100% accurate.\n"
     ]
    }
   ],
   "source": [
    "# Few Shot learning\n",
    "\n",
    "few_shot_prompt = f\"\"\" \n",
    "* You are a human activity recognition model.\n",
    "* Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sittting, Laying, Walking Upstairs, Walking Downstairs. \n",
    "* Provide the sentiment label and a brief explanation of your reasoning. \n",
    "\n",
    "Here are some examples:\n",
    "1.Dataset of laying: {laying_df}\n",
    "2.Dataset of sitting: {sitting_df}\n",
    "3.Dataset of standing: {standing_df}\n",
    "4.Dataset of walking: {walking_df}\n",
    "5.Dataset of walking downstairs: {downstairs_df}\n",
    "6.Dataset of walking upstairs: {upstairs_df}\n",
    "\n",
    "Here is the accelerometer data:\n",
    "{df1}, \n",
    "{df2},\n",
    "{df3},\n",
    "{df4},\n",
    "{df5},\n",
    "{df6}\n",
    "\n",
    "Please classify the activity for these six accelerometer data using the dataset of sample activites.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "few_shot_answer = llm.invoke(few_shot_prompt)\n",
    "print(few_shot_answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Quantitatively compare the accuracy of Few-Shot Learning with Decision Trees (You may use a subset of the test set if you encounter rate-limiting issues). Which method performs better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: What are the limitations of Zero-Shot Learning and Few-Shot Learning in the context of classifying human activities based on featurized accelerometer data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations of Zero Shot Learning in this activities are:\n",
    "\n",
    "    1. It's whole accuracy is fully dependent on the given prompt and how well it is designed. A poor designed prompt will not give us better accuracy in output. \n",
    "\n",
    "    2. It does not accurately specify in the activities due to small changes or similarity in different activities dataset.  \n",
    "\n",
    "    3. It feels difficulties in distinguishing between various activities, like, distinguishing between \"Running\" and \"Walking\", similarly with \"Sitting\" and \"Laying\". Because there is no significant movement in both the datasets, it is giving wrong output with respect to the acivity. \n",
    "\n",
    "\n",
    "\n",
    "Limitations of Few Shot Learning in this activities are:\n",
    "\n",
    "    1. It is depended on the quality of samples given in prompt. If the examples are not choosen well or do no have enough information it can lead to wrong output. Poor data representation can lead to inappropriate outputs\n",
    "\n",
    "    2. It typically relies on the limited number of samples which can lead to  create bias in output and may be possible that it does not capture full diversity or does not generalize well.\n",
    "\n",
    "    3. Because there is small number of samples it can lead to the overfiiting to the provided examples. It might be perform well for given examples but not with test or unseen data. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What does the model classify when given input from an entirely new activity that it hasn't seen before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In Zero Shot Learning, if we given input from entirely new activity then the model will try to classify the new activity with the help of existing knowledge and any information which is available. It might be not accurate but if there is no such relation between the old activities and new activities then it might be not able to classify or recongnize it properly. \n",
    "\n",
    "2. In Few Shot learning, we provide some examples related to the new activity which helps the model to learn, recognize and classify it properly. It uses the examples to understand the pattern of features of activity. And with the help of these, it can give more accurate answers and classify it better. But also, the accuracy will depend on how well the examples are presented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided accelerometer data, I will classify each activity as follows:\n",
      "\n",
      "1. accx,accy,accz\n",
      "0.05378475,0.8970043,0.4434115\n",
      "...\n",
      "0.02150611,0.8828317,0.4510561\n",
      "\n",
      "This activity is classified as **Laying**. The reason for this classification is that the accelerometer data shows a relatively stable and consistent pattern, with minimal changes in acceleration. This is consistent with the laying activity, where the person is stationary and not moving.\n",
      "\n",
      "2. accx,accy,accz\n",
      "1.271286,0.198344,0.2454702\n",
      "...\n",
      "1.388307,-0.141976,0.0764643\n",
      "\n",
      "This activity is classified as **Sitting**. The reason for this classification is that the accelerometer data shows a moderate level of acceleration, with some variation in the x, y, and z axes. This is consistent with the sitting activity, where the person is stationary but may be moving slightly.\n",
      "\n",
      "3. accx,accy,accz\n",
      "0.9362124,0.2966921,0.2259779\n",
      "...\n",
      "0.9445192,0.2983532,0.2130758\n",
      "\n",
      "This activity is classified as **Standing**. The reason for this classification is that the accelerometer data shows a relatively stable and consistent pattern, with minimal changes in acceleration. This is consistent with the standing activity, where the person is stationary and not moving.\n",
      "\n",
      "4. accx,accy,accz\n",
      "0.9937554,-0.02417739,0.2420851\n",
      "...\n",
      "0.9590432,-0.2697655,0.07142088\n",
      "\n",
      "This activity is classified as **Walking**. The reason for this classification is that the accelerometer data shows a moderate to high level of acceleration, with significant changes in the x, y, and z axes. This is consistent with the walking activity, where the person is moving and experiencing changes in acceleration.\n",
      "\n",
      "5. accx,accy,accz\n",
      "0.6403903,-0.1828193,0.0477\n",
      "...\n",
      "0.9184522,-0.1956053,0.02217104\n",
      "\n",
      "This activity is classified as **Walking Downstairs**. The reason for this classification is that the accelerometer data shows a moderate to high level of acceleration, with significant changes in the x, y, and z axes. This is consistent with the walking downstairs activity, where the person is moving and experiencing changes in acceleration.\n",
      "\n",
      "6. accx,accy,accz\n",
      "1.288792,0.02881073,0.1237082\n",
      "...\n",
      "1.388307,-0.141976,0.0764643\n",
      "\n",
      "This activity is classified as **Walking Upstairs**. The reason for this classification is that the accelerometer data shows a moderate to high level of acceleration, with significant changes in the x, y, and z axes. This is consistent with the walking upstairs activity, where the person is moving and experiencing changes in acceleration.\n",
      "\n",
      "Note that these classifications are based on the patterns and characteristics of the accelerometer data, and may not be 100% accurate. However, based on the provided data, these classifications are the most likely.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "Groq_Token = os.getenv('api_key')\n",
    "\n",
    "# Define model mapping and select the model\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\": \"llama3-8b-8192\",\n",
    "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
    "    \"gemma-9b\": \"gemma2-9b-it\"\n",
    "}\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "\n",
    "# Load test data\n",
    "file_paths = {\n",
    "    \"LAYING\": \"Combined/Test/LAYING/Subject_4.csv\",\n",
    "    \"WALKING\": \"Combined/Test/WALKING/Subject_4.csv\",\n",
    "    \"SITTING\": \"Combined/Test/SITTING/Subject_4.csv\",\n",
    "    \"STANDING\": \"Combined/Test/STANDING/Subject_4.csv\",\n",
    "    \"WALKING_UPSTAIRS\": \"Combined/Test/WALKING_UPSTAIRS/Subject_4.csv\",\n",
    "    \"WALKING_DOWNSTAIRS\": \"Combined/Test/WALKING_DOWNSTAIRS/Subject_4.csv\"\n",
    "}\n",
    "\n",
    "dataframes = {key: pd.read_csv(path) for key, path in file_paths.items()}\n",
    "\n",
    "# Convert DataFrames to CSV strings\n",
    "data_strings = {key: df.head(70).to_csv(index=False) for key, df in dataframes.items()}\n",
    "\n",
    "# Load training data\n",
    "train_file_paths = {\n",
    "    \"LAYING\": \"Combined/Train/LAYING/Subject_1.csv\",\n",
    "    \"SITTING\": \"Combined/Train/SITTING/Subject_1.csv\",\n",
    "    \"STANDING\": \"Combined/Train/STANDING/Subject_1.csv\",\n",
    "    \"WALKING\": \"Combined/Train/WALKING/Subject_1.csv\",\n",
    "    \"WALKING_DOWNSTAIRS\": \"Combined/Train/WALKING_DOWNSTAIRS/Subject_1.csv\",\n",
    "    \"WALKING_UPSTAIRS\": \"Combined/Train/WALKING_UPSTAIRS/Subject_1.csv\"\n",
    "}\n",
    "\n",
    "train_dataframes = {key: pd.read_csv(path) for key, path in train_file_paths.items()}\n",
    "\n",
    "# Convert training DataFrames to CSV strings\n",
    "train_data_strings = {key: df.head(50).to_csv(index=False) for key, df in train_dataframes.items()}\n",
    "\n",
    "# Create the few-shot learning prompt\n",
    "few_shot_prompt = f\"\"\"\n",
    "You are a human activity recognition model.\n",
    "Your task is to classify the following accelerometer data into one of the six activities: Walking, Standing, Sitting, Laying, Walking Upstairs, Walking Downstairs.\n",
    "Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are some examples:\n",
    "1. Dataset of laying: {train_data_strings['LAYING']}\n",
    "2. Dataset of sitting: {train_data_strings['SITTING']}\n",
    "3. Dataset of standing: {train_data_strings['STANDING']}\n",
    "4. Dataset of walking: {train_data_strings['WALKING']}\n",
    "5. Dataset of walking downstairs: {train_data_strings['WALKING_DOWNSTAIRS']}\n",
    "6. Dataset of walking upstairs: {train_data_strings['WALKING_UPSTAIRS']}\n",
    "\n",
    "Using these examples, try to classify the following accelerometer data:\n",
    "1. {data_strings['LAYING']}\n",
    "2. {data_strings['WALKING']}\n",
    "3. {data_strings['SITTING']}\n",
    "4. {data_strings['STANDING']}\n",
    "5. {data_strings['WALKING_UPSTAIRS']}\n",
    "6. {data_strings['WALKING_DOWNSTAIRS']}\n",
    "\n",
    "Please classify the activity for these six accelerometer data using the dataset of sample activities.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke the model\n",
    "try:\n",
    "    few_shot_answer = llm.invoke(few_shot_prompt)\n",
    "    print(few_shot_answer.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
